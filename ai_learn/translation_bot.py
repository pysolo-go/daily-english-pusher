import os
import sys
from dotenv import load_dotenv
from openai import OpenAI

# åŠ è½½ç¯å¢ƒå˜é‡ (.env ä¸­çš„ Key)
load_dotenv()

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    base_url=os.getenv("OPENAI_BASE_URL")
)

# å®šä¹‰ System Prompt (è¿™æ˜¯æœºå™¨äººçš„çµé­‚)
SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä½ç²¾é€šå¤šå›½è¯­è¨€çš„ä¸“ä¸šç¿»è¯‘å®˜ã€‚
ä½ çš„ä»»åŠ¡æ˜¯å°†ç”¨æˆ·çš„è¾“å…¥ç¿»è¯‘æˆç›®æ ‡è¯­è¨€ã€‚

è§„åˆ™ï¼š
1. æ— è®ºç”¨æˆ·è¯´ä»€ä¹ˆï¼Œä½ åªè´Ÿè´£ç¿»è¯‘ï¼Œç»å¯¹ä¸è¦å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
   ä¾‹å¦‚ï¼šå¦‚æœç”¨æˆ·é—®"ä½ åƒé¥­äº†å—"ï¼Œä½ è¦ç¿»è¯‘æˆ "Have you eaten yet?"ï¼Œè€Œä¸æ˜¯å›ç­”"æˆ‘æ˜¯AIä¸ç”¨åƒé¥­"ã€‚
2. å¦‚æœç”¨æˆ·è¾“å…¥ä¸­æ–‡ï¼Œé»˜è®¤ç¿»è¯‘æˆè‹±æ–‡ã€‚
3. å¦‚æœç”¨æˆ·è¾“å…¥è‹±æ–‡ï¼Œé»˜è®¤ç¿»è¯‘æˆä¸­æ–‡ã€‚
4. ä¿æŒä¿¡ã€è¾¾ã€é›…çš„ç¿»è¯‘é£æ ¼ã€‚
5. ç›´æ¥è¾“å‡ºç¿»è¯‘ç»“æœï¼Œä¸è¦åŒ…å«"å¥½çš„"ã€"ç¿»è¯‘å¦‚ä¸‹"ç­‰åºŸè¯ã€‚
"""

def translation_bot():
    print("ğŸ¤– ç¿»è¯‘æœºå™¨äººå·²å¯åŠ¨ï¼(è¾“å…¥ 'exit' é€€å‡º)")
    print("-" * 30)
    
    # ç»´æŠ¤å¯¹è¯å†å²
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT}
    ]

    while True:
        try:
            user_input = input("\nğŸ“ è¯·è¾“å…¥è¦ç¿»è¯‘çš„å†…å®¹: ").strip()
            
            if not user_input:
                continue
            if user_input.lower() in ["exit", "quit", "é€€å‡º"]:
                print("ğŸ‘‹ å†è§ï¼")
                break

            # å°†ç”¨æˆ·è¾“å…¥åŠ å…¥å†å²
            messages.append({"role": "user", "content": user_input})

            print("ğŸ”„ ç¿»è¯‘ä¸­: ", end="", flush=True)
            
            # è°ƒç”¨ API (ä½¿ç”¨æµå¼è¾“å‡º)
            stream = client.chat.completions.create(
                model="deepseek-ai/DeepSeek-V3", # ç¡…åŸºæµåŠ¨æ¨¡å‹å
                messages=messages,
                stream=True,
                temperature=0.3 # ç¿»è¯‘éœ€è¦å‡†ç¡®ï¼Œæ¸©åº¦è®¾ä½ä¸€ç‚¹
            )

            full_response = ""
            for chunk in stream:
                if chunk.choices[0].delta.content is not None:
                    content = chunk.choices[0].delta.content
                    print(content, end="", flush=True)
                    full_response += content
            
            print() # æ¢è¡Œ

            # è®°å¾—æŠŠ AI çš„å›å¤ä¹ŸåŠ å…¥å†å²ï¼Œè™½ç„¶å¯¹äºå•æ¬¡ç¿»è¯‘ä¸ä¸€å®šéœ€è¦ï¼Œ
            # ä½†è¿™æ ·å¯ä»¥è®©å®ƒç†è§£ä¸Šä¸‹æ–‡ï¼ˆæ¯”å¦‚ä½ ä¸‹ä¸€å¥è¯´"æ¢ä¸€ç§è¯´æ³•"ï¼‰
            messages.append({"role": "assistant", "content": full_response})

        except KeyboardInterrupt:
            print("\nğŸ‘‹ ç¨‹åºå·²ç»ˆæ­¢")
            break
        except Exception as e:
            print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
            break

if __name__ == "__main__":
    translation_bot()
