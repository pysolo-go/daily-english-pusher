import os
import time
from dotenv import load_dotenv
from openai import OpenAI

# 1. åŠ è½½ç¯å¢ƒå˜é‡
# è¿™è¡Œä»£ç ä¼šè‡ªåŠ¨å¯»æ‰¾å½“å‰ç›®å½•ä¸‹çš„ .env æ–‡ä»¶ï¼Œå¹¶åŠ è½½é‡Œé¢çš„å˜é‡
# å¦‚æœæ‰¾ä¸åˆ° .envï¼Œå®ƒä¼šä»€ä¹ˆéƒ½ä¸åšï¼ˆæ‰€ä»¥è®°å¾—åˆ›å»º .envï¼ï¼‰
load_dotenv()

# 2. åˆå§‹åŒ–å®¢æˆ·ç«¯
# OpenAI SDK æ˜¯ç›®å‰è¡Œä¸šçš„â€œé€šç”¨æ ‡å‡†â€ã€‚
# æ— è®ºæ˜¯ OpenAI, DeepSeek, Moonshot (Kimi), è¿˜æ˜¯æœ¬åœ°çš„ Ollama/vLLMï¼Œ
# åªè¦æ”¯æŒ "OpenAI Compatible" åè®®ï¼Œéƒ½å¯ä»¥ç”¨è¿™ä¸ª SDK è°ƒç”¨ã€‚
api_key = os.getenv("OPENAI_API_KEY")
base_url = os.getenv("OPENAI_BASE_URL")

if not api_key:
    print("âš ï¸ è­¦å‘Š: æœªæ£€æµ‹åˆ° OPENAI_API_KEY ç¯å¢ƒå˜é‡ã€‚")
    print("è¯·å¤åˆ¶ .env.example ä¸º .env å¹¶å¡«å…¥ä½ çš„ Keyã€‚")
    # ä¸ºäº†æ¼”ç¤ºä¸æŠ¥é”™ï¼Œæˆ‘ä»¬ç»™ä¸ªå‡çš„ï¼Œå®é™…è°ƒç”¨ä¼šå¤±è´¥
    api_key = "sk-demo-key"

client = OpenAI(
    api_key=api_key,
    base_url=base_url  # å¦‚æœä¸å¡«ï¼Œé»˜è®¤æ˜¯ https://api.openai.com/v1
)

def demo_simple_chat():
    """
    æ¼”ç¤º 1: æœ€åŸºç¡€çš„å¯¹è¯ (ä¸€æ¬¡æ€§ç­‰å¾…ç»“æœ)
    """
    print("\n--- 1. ç®€å•å¯¹è¯ (éæµå¼) ---")
    print("æ­£åœ¨æ€è€ƒä¸­ (ç­‰å¾…å®Œæ•´å›å¤)...")
    
    try:
        response = client.chat.completions.create(
            model="deepseek-ai/DeepSeek-V3",  # ç¡…åŸºæµåŠ¨çš„æ¨¡å‹åç§°é€šå¸¸æ˜¯ ç»„ç»‡/æ¨¡å‹å
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå¹½é»˜çš„è„±å£ç§€æ¼”å‘˜ã€‚"},
                {"role": "user", "content": "è®²ä¸ªå…³äºç¨‹åºå‘˜çš„ç¬‘è¯ã€‚"}
            ]
        )
        # è·å–å®Œæ•´å†…å®¹
        content = response.choices[0].message.content
        print(f"ğŸ¤– AI: {content}")
        
    except Exception as e:
        print(f"âŒ è°ƒç”¨å¤±è´¥ (å¯èƒ½æ˜¯ Key æ— æ•ˆ): {e}")

def demo_stream_chat():
    """
    æ¼”ç¤º 2: æµå¼è¾“å‡º (Streaming)
    è¿™æ˜¯æå‡ç”¨æˆ·ä½“éªŒçš„å…³é”®ï¼ä¸ç”¨ç­‰ AI å†™å®Œå‡ ç™¾å­—æ‰æ˜¾ç¤ºï¼Œè€Œæ˜¯å†™ä¸€ä¸ªå­—æ˜¾ç¤ºä¸€ä¸ªå­—ã€‚
    """
    print("\n--- 2. æµå¼å¯¹è¯ (Streaming) ---")
    print("ğŸ¤– AI: ", end="", flush=True)
    
    try:
        stream = client.chat.completions.create(
            model="deepseek-ai/DeepSeek-V3",
            messages=[
                {"role": "user", "content": "è¯·ç”¨ 50 ä¸ªå­—è§£é‡Šä»€ä¹ˆæ˜¯ APIã€‚"}
            ],
            stream=True  # <--- å…³é”®å‚æ•°
        )
        
        # é€å—æ¥æ”¶æ•°æ®
        for chunk in stream:
            if chunk.choices[0].delta.content is not None:
                content = chunk.choices[0].delta.content
                print(content, end="", flush=True)
                time.sleep(0.05)  # æ¨¡æ‹Ÿæ‰“å­—æœºæ•ˆæœ (å®é™…ä¸éœ€è¦ sleep)
        print() # æ¢è¡Œ
        
    except Exception as e:
        print(f"\nâŒ æµå¼è°ƒç”¨å¤±è´¥: {e}")

def demo_chat_with_history():
    """
    æ¼”ç¤º 3: å¸¦è®°å¿†çš„å¯¹è¯ (Session Management)
    API æœ¬èº«æ˜¯â€œæ— çŠ¶æ€â€çš„ (Stateless)ï¼Œå®ƒè®°ä¸ä½ä½ ä¸Šä¸€å¥è¯´äº†ä»€ä¹ˆã€‚
    å¦‚æœè¦å®ç°è¿ç»­å¯¹è¯ï¼Œæˆ‘ä»¬éœ€è¦è‡ªå·±ç»´æŠ¤ä¸€ä¸ª messages åˆ—è¡¨ï¼Œ
    æ¯æ¬¡æŠŠä¹‹å‰çš„å¯¹è¯å†å²éƒ½å‘ç»™å®ƒã€‚
    """
    print("\n--- 3. å¸¦è®°å¿†çš„è¿ç»­å¯¹è¯ (è¾“å…¥ 'exit' é€€å‡º) ---")
    
    # åˆå§‹åŒ–å¯¹è¯å†å² (é€šå¸¸åŒ…å« System Prompt)
    messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„ AI åŠ©æ‰‹ã€‚"}
    ]
    
    while True:
        user_input = input("\nğŸ‘¤ ä½ : ")
        if user_input.lower() in ["exit", "quit", "é€€å‡º"]:
            break
            
        # 1. æŠŠç”¨æˆ·çš„è¯åŠ å…¥å†å²
        messages.append({"role": "user", "content": user_input})
        
        try:
            print("ğŸ¤– AI: ", end="", flush=True)
            full_response = ""
            
            # 2. æŠŠæ•´ä¸ªå†å²å‘ç»™ API
            stream = client.chat.completions.create(
                model="deepseek-ai/DeepSeek-V3",
                messages=messages, # <--- é‡ç‚¹ï¼šå‘é€å®Œæ•´å†å²
                stream=True
            )
            
            for chunk in stream:
                if chunk.choices[0].delta.content is not None:
                    content = chunk.choices[0].delta.content
                    print(content, end="", flush=True)
                    full_response += content
            
            # 3. æŠŠ AI çš„å›ç­”ä¹ŸåŠ å…¥å†å² (è¿™æ ·ä¸‹ä¸€è½®å®ƒå°±çŸ¥é“äº†)
            messages.append({"role": "assistant", "content": full_response})
            
        except Exception as e:
            print(f"\nâŒ å‡ºé”™: {e}")
            break

if __name__ == "__main__":
    # æç¤ºï¼šå¦‚æœæ²¡æœ‰çœŸå® Keyï¼Œè¿è¡Œè¿™äº›ä¼šæŠ¥é”™ã€‚
    # è¿™æ˜¯æ­£å¸¸çš„ï¼Œé‡ç‚¹æ˜¯ç†è§£ä»£ç é€»è¾‘ã€‚
    print(">>> å¼€å§‹æ¼”ç¤º LLM API è°ƒç”¨ <<<")
    print(f"å½“å‰é…ç½® Base URL: {client.base_url}")
    
    # åªè¦ Key æ˜¯æ— æ•ˆçš„ï¼Œè¿™é‡Œè‚¯å®šä¼šæŠ¥é”™ï¼Œæˆ‘ä»¬æ•è·ä¸€ä¸‹ä¸è®©ç¨‹åºå´©æ‰
    # å»ºè®®å» .env å¡«å…¥çœŸå®çš„ Key (æ¯”å¦‚ DeepSeek çš„) æ¥ä½“éªŒ
    demo_simple_chat()
    demo_stream_chat()
    demo_chat_with_history()
