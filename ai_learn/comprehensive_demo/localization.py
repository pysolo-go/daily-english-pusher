
import streamlit as st

TRANSLATIONS = {
    "Home": {
        "page_title": {"en": "AI Learning Hub", "zh": "AI å…¨æ ˆå­¦ä¹ é©¾é©¶èˆ±"},
        "title": {"en": "ğŸš€ AI Full Stack Learning Platform", "zh": "ğŸš€ AI å…¨æ ˆå­¦ä¹ ç»¼åˆæ¼”ç»ƒå¹³å°"},
        "welcome": {
            "en": """
### Welcome to your AI Learning Cockpit!

Here integrates the core technologies you have learned so far. You can choose different modules in the left sidebar to practice:

*   **ğŸ¤– Basic Chat**: Experience basic LLM chat and Prompt engineering.
*   **ğŸ“š RAG + Rerank**: Experience the RAG pipeline and compare the effect of Rerank.
*   **ğŸ•¸ï¸ Knowledge Graph**: Extract entity relationships from text and visualize them.
*   **ğŸ§© Agent Basics**: Experience ReAct pattern, let AI use tools (Math, Weather, Wikipedia).
*   **ğŸ”„ Agent Workflow**: Experience event-driven workflows (Generator-Critic Loop) for self-reflection.
*   **ğŸ¤ Multi-Agent**: Experience collaboration between Researcher and Writer agents.
*   **ğŸ› ï¸ Finetune Data**: Prepare JSONL dataset for model training.
*   **ğŸ§  PEFT/LoRA**: Learn the concepts behind efficient fine-tuning.

---
#### Current Status
*   **Environment**: Mac OS
*   **Model Provider**: SiliconFlow (DeepSeek/Qwen)
*   **Frameworks**: LlamaIndex, Streamlit
""",
            "zh": """
### æ¬¢è¿æ¥åˆ°ä½ çš„ AI å­¦ä¹ é©¾é©¶èˆ±ï¼

è¿™é‡Œé›†æˆäº†ä½ ç›®å‰å­¦åˆ°çš„æ ¸å¿ƒæŠ€æœ¯ï¼Œå¯ä»¥åœ¨å·¦ä¾§å¯¼èˆªæ é€‰æ‹©ä¸åŒçš„æ¨¡å—è¿›è¡Œç»ƒä¹ ï¼š

*   **ğŸ¤– åŸºç¡€å¯¹è¯ (Basic Chat)**: ä½“éªŒæœ€åŸºç¡€çš„ LLM å¯¹è¯ä¸ Prompt æ•ˆæœã€‚
*   **ğŸ“š å¢å¼ºæ£€ç´¢ (RAG + Rerank)**: ä½“éªŒ RAG æµç¨‹ï¼Œå¹¶å¯¹æ¯”å¼€å¯/å…³é—­ "é‡æ’åº (Rerank)" çš„æ•ˆæœå·®å¼‚ã€‚
*   **ğŸ•¸ï¸ çŸ¥è¯†å›¾è°± (Knowledge Graph)**: è¾“å…¥æ–‡æœ¬ï¼Œè‡ªåŠ¨æå–å®ä½“å…³ç³»å¹¶å¯è§†åŒ–ï¼Œä½“éªŒå¤šè·³æ¨ç†ã€‚
*   **ğŸ§© æ™ºèƒ½ä½“åŸºç¡€ (Agent Basics)**: ä½“éªŒ ReAct æ¨¡å¼ï¼Œè®© AI å­¦ä¼šä½¿ç”¨å·¥å…· (å¤©æ°”ã€æ•°å­¦ã€ç»´åŸºç™¾ç§‘)ã€‚
*   **ğŸ”„ æ™ºèƒ½ä½“å·¥ä½œæµ (Agent Workflow)**: ä½“éªŒäº‹ä»¶é©±åŠ¨çš„å·¥ä½œæµ (Generator-Critic Loop)ï¼Œè®© AI å…·å¤‡åæ€ä¸è‡ªæˆ‘ä¿®æ­£èƒ½åŠ›ã€‚
*   **ğŸ¤ å¤šæ™ºèƒ½ä½“åä½œ (Multi-Agent)**: ä½“éªŒç ”ç©¶å‘˜ (Researcher) ä¸ä½œå®¶ (Writer) çš„åä½œæµç¨‹ã€‚
*   **ğŸ› ï¸ å¾®è°ƒæ•°æ®å‡†å¤‡ (Finetune Data)**: å‡†å¤‡ JSONL æ ¼å¼çš„è®­ç»ƒæ•°æ®ã€‚
*   **ğŸ§  PEFT/LoRA åŸç†**: å­¦ä¹ é«˜æ•ˆå¾®è°ƒçš„æ ¸å¿ƒæ¦‚å¿µã€‚

---
#### å½“å‰çŠ¶æ€
*   **Environment**: Mac OS
*   **Model Provider**: SiliconFlow (DeepSeek/Qwen)
*   **Frameworks**: LlamaIndex, Streamlit
"""
        },
        "sidebar_tip": {"en": "Please select a demo page above to start!", "zh": "è¯·åœ¨ä¸Šæ–¹é€‰æ‹©ä¸€ä¸ªæ¼”ç¤ºé¡µé¢ (Pages) å¼€å§‹ç»ƒä¹ ï¼"}
    },
    "Basic_Chat": {
        "page_title": {"en": "Basic Chat", "zh": "åŸºç¡€å¯¹è¯"},
        "header": {"en": "ğŸ¤– Basic Chat & Translator", "zh": "ğŸ¤– åŸºç¡€å¯¹è¯ & ç¿»è¯‘åŠ©æ‰‹"},
        "model_config": {"en": "Model Configuration", "zh": "æ¨¡å‹é…ç½®"},
        "provider_select": {"en": "Model Provider", "zh": "æ¨¡å‹æœåŠ¡å•†"},
        "model_select": {"en": "Model Name", "zh": "æ¨¡å‹åç§°"},
        "temperature": {"en": "Temperature (Creativity)", "zh": "Temperature (åˆ›é€ åŠ›)"},
        "system_prompt": {"en": "System Prompt (Persona)", "zh": "System Prompt (äººè®¾)"},
        "system_prompt_default": {
            "en": "You are a helpful AI assistant. Answer in the language of the user's question.", 
            "zh": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„ AI åŠ©æ‰‹ã€‚è¯·ç”¨ç”¨æˆ·æé—®çš„è¯­è¨€å›ç­”ã€‚"
        },
        "input_placeholder": {"en": "Enter your question...", "zh": "è¯·è¾“å…¥ä½ çš„é—®é¢˜..."},
    },
    "RAG_Rerank": {
        "page_title": {"en": "RAG + Rerank", "zh": "RAG + Rerank"},
        "header": {"en": "ğŸ“š RAG Enhanced Retrieval (Rerank Comparison)", "zh": "ğŸ“š RAG å¢å¼ºæ£€ç´¢ (Rerank å¯¹æ¯”)"},
        "data_prep": {"en": "1. Data Preparation", "zh": "1. æ•°æ®å‡†å¤‡"},
        "data_source": {"en": "Select Data Source", "zh": "é€‰æ‹©æ•°æ®æ¥æº"},
        "source_options": {"en": ["Use Sample Text", "Upload File (Coming Soon)"], "zh": ["ä½¿ç”¨ç¤ºä¾‹æ–‡æœ¬", "ä¸Šä¼ æ–‡ä»¶ (æš‚æœªå¼€æ”¾)"]},
        "input_label": {"en": "Input Text for Retrieval", "zh": "è¾“å…¥éœ€è¦æ£€ç´¢çš„æ–‡æœ¬"},
        "build_index": {"en": "ğŸ”„ Build/Rebuild Index", "zh": "ğŸ”„ æ„å»º/é‡å»º ç´¢å¼•"},
        "indexing": {"en": "Slicing and Vectorizing...", "zh": "æ­£åœ¨åˆ‡ç‰‡å¹¶å‘é‡åŒ–..."},
        "index_success": {"en": "Index Built Successfully!", "zh": "ç´¢å¼•æ„å»ºå®Œæˆï¼"},
        "qa_retrieval": {"en": "2. Q&A and Retrieval", "zh": "2. æé—®ä¸æ£€ç´¢"},
        "build_index_first": {"en": "ğŸ‘ˆ Please build index on the left first", "zh": "ğŸ‘ˆ è¯·å…ˆåœ¨å·¦ä¾§æ„å»ºç´¢å¼•"},
        "query_placeholder": {"en": "Enter your question", "zh": "è¯·è¾“å…¥é—®é¢˜"},
        "query_default": {"en": "What is the invoice amount for ByteDance?", "zh": "è´­ä¹°æ–¹æ˜¯å­—èŠ‚è·³åŠ¨çš„å‘ç¥¨é‡‘é¢æ˜¯å¤šå°‘ï¼Ÿ"},
        "enable_rerank": {"en": "Enable Rerank", "zh": "å¯ç”¨é‡æ’åº (Rerank)"},
        "top_k": {"en": "Initial Retrieval (Top K)", "zh": "åˆç­›æ•°é‡ (Top K)"},
        "top_n": {"en": "Rerank Retention (Top N)", "zh": "é‡æ’åä¿ç•™ (Top N)"},
        "start_retrieval": {"en": "ğŸ” Start Retrieval", "zh": "ğŸ” å¼€å§‹æ£€ç´¢"},
        "thinking": {"en": "AI Thinking...", "zh": "AI æ€è€ƒä¸­..."},
        "answer": {"en": "### ğŸ¤– Answer", "zh": "### ğŸ¤– å›ç­”"},
        "source_nodes": {"en": "View Source Nodes", "zh": "æŸ¥çœ‹ AI æ£€ç´¢åˆ°çš„å‚è€ƒç‰‡æ®µ (Source Nodes)"},
    },
    "Knowledge_Graph": {
        "page_title": {"en": "Knowledge Graph", "zh": "çŸ¥è¯†å›¾è°±"},
        "header": {"en": "ğŸ•¸ï¸ Knowledge Graph Construction & Visualization", "zh": "ğŸ•¸ï¸ çŸ¥è¯†å›¾è°±æ„å»ºä¸å¯è§†åŒ–"},
        "text_input": {"en": "1. Text Input", "zh": "1. æ–‡æœ¬è¾“å…¥"},
        "input_label": {"en": "Input Text (Supports Chinese)", "zh": "è¾“å…¥æ–‡æœ¬ (æ”¯æŒä¸­æ–‡)"},
        "generate_btn": {"en": "ğŸš€ Generate Graph", "zh": "ğŸš€ ç”Ÿæˆå›¾è°±"},
        "generating": {"en": "Analyzing Entity Relationships (may take seconds)...", "zh": "æ­£åœ¨åˆ†æå®ä½“å…³ç³» (è¿™å¯èƒ½éœ€è¦å‡ åç§’)..."},
        "success_msg": {"en": "Graph Constructed! Found {} relationships.", "zh": "å›¾è°±æ„å»ºå®Œæˆï¼å‘ç° {} æ¡å…³ç³»ã€‚"},
        "graph_query": {"en": "2. Graph Query", "zh": "2. å›¾è°±æŸ¥è¯¢"},
        "query_placeholder": {"en": "Ask the Graph", "zh": "å‘å›¾è°±æé—®"},
        "query_default": {"en": "What is the relationship between Elon Musk and NASA?", "zh": "ä¼Šéš†Â·é©¬æ–¯å…‹å’Œ NASA æœ‰ä»€ä¹ˆå…³ç³»ï¼Ÿ"},
        "query_btn": {"en": "ğŸ” Query", "zh": "ğŸ” æŸ¥è¯¢"},
        "reasoning": {"en": "Reasoning...", "zh": "æ¨ç†ä¸­..."},
        "answer": {"en": "### ğŸ¤– Answer", "zh": "### ğŸ¤– å›ç­”"},
        "visualization": {"en": "3. Visualization", "zh": "3. å¯è§†åŒ–å±•ç¤º"},
        "viz_placeholder": {"en": "Graph will be displayed here after generation", "zh": "ç”Ÿæˆå›¾è°±ååœ¨æ­¤å¤„æ˜¾ç¤º"},
    },
    "Agent_Basics": {
        "page_title": {"en": "Agent Basics", "zh": "æ™ºèƒ½ä½“åŸºç¡€"},
        "title": {"en": "ğŸ¤– Agent Basics: ReAct Pattern", "zh": "ğŸ¤– æ™ºèƒ½ä½“åŸºç¡€: ReAct æ¨¡å¼"},
        "description": {
            "en": """
This module demonstrates a basic **ReAct (Reasoning + Acting)** Agent.
The Agent has access to **4 tools**, showing how agents can interact with different systems:

1. `multiply(a, b)`: **Math** (Logic)
2. `get_weather(city)`: **Real-time API** (External Data via wttr.in)
3. `search_wikipedia(query)`: **Knowledge** (Encyclopedia via Wikipedia)
4. `get_system_time()`: **System State** (Local environment)

The Agent will **reason** about your query and **decide** which tool(s) to call.
""",
            "zh": """
æœ¬æ¨¡å—æ¼”ç¤ºäº†ä¸€ä¸ªåŸºç¡€çš„ **ReAct (Reasoning + Acting)** æ™ºèƒ½ä½“ã€‚
è¯¥æ™ºèƒ½ä½“å¯ä»¥ä½¿ç”¨ **4 ä¸ªå·¥å…·**ï¼Œå±•ç¤ºäº† AI å¦‚ä½•ä¸ä¸åŒç³»ç»Ÿäº¤äº’ï¼š

1. `multiply(a, b)`: **æ•°å­¦è®¡ç®—** (é€»è¾‘èƒ½åŠ›)
2. `get_weather(city)`: **å®æ—¶å¤©æ°”** (å¤–éƒ¨æ•°æ®ï¼Œé€šè¿‡ wttr.in)
3. `search_wikipedia(query)`: **ç»´åŸºç™¾ç§‘** (çŸ¥è¯†åº“)
4. `get_system_time()`: **ç³»ç»Ÿæ—¶é—´** (æœ¬åœ°ç¯å¢ƒçŠ¶æ€)

æ™ºèƒ½ä½“ä¼šå¯¹ä½ çš„é—®é¢˜è¿›è¡Œ **æ¨ç†**ï¼Œå¹¶ **å†³å®š** è°ƒç”¨å“ªäº›å·¥å…·ã€‚
"""
        },
        "history_logs": {"en": "ğŸ” Historical Logs", "zh": "ğŸ” å†å²æ—¥å¿—"},
        "input_placeholder": {"en": "Try: 'Weather in Tokyo?', 'Who is Elon Musk?', 'Time now?', '25*4?'", "zh": "å°è¯•è¾“å…¥ï¼š'ä¸œäº¬å¤©æ°”å¦‚ä½•ï¼Ÿ'ï¼Œ'è°æ˜¯é©¬æ–¯å…‹ï¼Ÿ'ï¼Œ'ç°åœ¨å‡ ç‚¹ï¼Ÿ'ï¼Œ'25ä¹˜ä»¥4ç­‰äºå¤šå°‘ï¼Ÿ'"},
        "reasoning_logs": {"en": "ğŸ” Reasoning & Tool Logs", "zh": "ğŸ” æ¨ç†ä¸å·¥å…·è°ƒç”¨æ—¥å¿—"},
        "no_logs": {"en": "No internal logs captured.", "zh": "æœªæ•è·åˆ°å†…éƒ¨æ—¥å¿—ã€‚"}
    },
    "Agent_Workflow": {
        "page_title": {"en": "Agent Workflow", "zh": "æ™ºèƒ½ä½“å·¥ä½œæµ"},
        "title": {"en": "ğŸ”„ Agent Workflow: Reflection Loop", "zh": "ğŸ”„ æ™ºèƒ½ä½“å·¥ä½œæµ: åæ€å¾ªç¯"},
        "description": {
            "en": """
This module demonstrates **LlamaIndex Workflows** (Event-Driven Architecture).
Unlike a simple linear chain, a Workflow can have **loops**, **branches**, and **state**.

**The Scenario: Joke Creator & Critic**
1.  **Creator**: Writes a joke about a topic.
2.  **Critic**: Reviews the joke and gives a score (1-10) and feedback.
3.  **Decision**: 
    -   If Score > 7: âœ… Success!
    -   If Score <= 7: âŒ Reject, send feedback back to Creator to improve.
""",
            "zh": """
æœ¬æ¨¡å—æ¼”ç¤ºäº† **LlamaIndex Workflows** (äº‹ä»¶é©±åŠ¨æ¶æ„)ã€‚
ä¸ç®€å•çš„çº¿æ€§é“¾ä¸åŒï¼Œå·¥ä½œæµå¯ä»¥åŒ…å« **å¾ªç¯**ã€**åˆ†æ”¯** å’Œ **çŠ¶æ€**ã€‚

**åœºæ™¯ï¼šç¬‘è¯åˆ›ä½œè€…ä¸è¯„è®ºå®¶**
1.  **åˆ›ä½œè€… (Creator)**: å›´ç»•ä¸»é¢˜åˆ›ä½œä¸€ä¸ªç¬‘è¯ã€‚
2.  **è¯„è®ºå®¶ (Critic)**: è¯„å®¡ç¬‘è¯å¹¶ç»™å‡ºè¯„åˆ† (1-10) å’Œåé¦ˆã€‚
3.  **å†³ç­–**: 
    -   å¦‚æœè¯„åˆ† > 7: âœ… æˆåŠŸï¼
    -   å¦‚æœè¯„åˆ† <= 7: âŒ æ‹’ç»ï¼Œå°†åé¦ˆå‘å›ç»™åˆ›ä½œè€…è¿›è¡Œæ”¹è¿›ã€‚
"""
        },
        "topic_input": {"en": "Enter a topic for the joke:", "zh": "è¾“å…¥ç¬‘è¯çš„ä¸»é¢˜ï¼š"},
        "start_btn": {"en": "Start Workflow", "zh": "å¼€å§‹å·¥ä½œæµ"},
        "running": {"en": "Running Workflow...", "zh": "æ­£åœ¨è¿è¡Œå·¥ä½œæµ..."},
        "final_result": {"en": "### ğŸ Final Result", "zh": "### ğŸ æœ€ç»ˆç»“æœ"},
        "error": {"en": "Workflow Error: {}", "zh": "å·¥ä½œæµé”™è¯¯: {}"},
        "generator_attempt": {"en": "**Attempt {} (Generator)**: Generating joke about '{}'...", "zh": "**å°è¯• {} (ç”Ÿæˆå™¨)**: æ­£åœ¨ç”Ÿæˆå…³äº '{}' çš„ç¬‘è¯..."},
        "generated_joke": {"en": "ğŸƒ **Generated Joke**: {}", "zh": "ğŸƒ **ç”Ÿæˆçš„ç¬‘è¯**: {}"},
        "max_attempts_reached": {"en": "Maximum attempts reached. The critic is too tough!", "zh": "è¾¾åˆ°æœ€å¤§å°è¯•æ¬¡æ•°ã€‚è¯„è®ºå®¶å¤ªä¸¥æ ¼äº†ï¼"},
        "generator_improve": {"en": "**Attempt {} (Generator)**: Improving joke based on feedback...", "zh": "**å°è¯• {} (ç”Ÿæˆå™¨)**: æ ¹æ®åé¦ˆæ”¹è¿›ç¬‘è¯..."},
        "critic_reviewing": {"en": "**Attempt {} (Critic)**: Reviewing...", "zh": "**å°è¯• {} (è¯„è®ºå®¶)**: æ­£åœ¨è¯„å®¡..."},
        "critic_review_output": {"en": "ğŸ§ **Critic Review**: {}", "zh": "ğŸ§ **è¯„è®ºå®¶è¯„å®¡**: {}"},
        "success_msg": {"en": "ğŸ‰ **Success!** Score {}/10 is good enough.", "zh": "ğŸ‰ **æˆåŠŸï¼** å¾—åˆ† {}/10 è¶³å¤Ÿå¥½äº†ã€‚"},
        "reject_msg": {"en": "âŒ **Rejected!** Score {}/10 is too low. Retrying...", "zh": "âŒ **æ‹’ç»ï¼** å¾—åˆ† {}/10 å¤ªä½ã€‚é‡è¯•ä¸­..."},
        "prompt_gen": {"en": "Tell me a short, funny joke about {}.", "zh": "ç»™æˆ‘è®²ä¸€ä¸ªå…³äº {} çš„ç®€çŸ­æœ‰è¶£çš„ç¬‘è¯ã€‚"},
        "prompt_improve": {
            "en": "The previous joke about {} was rejected.\nPrevious Joke: {}\nCritic Feedback: {}\nPlease write a BETTER, funnier joke considering the feedback.",
            "zh": "å…³äº {} çš„ä¸Šä¸€ä¸ªç¬‘è¯è¢«æ‹’ç»äº†ã€‚\nä¸Šä¸€ä¸ªç¬‘è¯: {}\nè¯„è®ºå®¶åé¦ˆ: {}\nè¯·æ ¹æ®åé¦ˆå†™ä¸€ä¸ªæ›´å¥½ã€æ›´æœ‰è¶£çš„ç¬‘è¯ã€‚"
        },
        "prompt_review": {
            "en": "Rate this joke on a scale of 1 to 10 (integer only) and give brief feedback.\nJoke: {}\nFormat: SCORE: <number>\nFEEDBACK: <text>",
            "zh": "è¯·å¯¹è¿™ä¸ªç¬‘è¯è¿›è¡Œè¯„åˆ†ï¼ˆ1åˆ°10åˆ†ï¼Œä»…æ•´æ•°ï¼‰å¹¶ç»™å‡ºç®€çŸ­åé¦ˆã€‚\nç¬‘è¯: {}\næ ¼å¼: SCORE: <æ•°å­—>\nFEEDBACK: <æ–‡æœ¬>"
        }
    },
    "Multi_Agent": {
        "page_title": {"en": "Multi-Agent Collaboration", "zh": "å¤šæ™ºèƒ½ä½“åä½œ"},
        "title": {"en": "ğŸ¤ Multi-Agent Collaboration: Research & Write", "zh": "ğŸ¤ å¤šæ™ºèƒ½ä½“åä½œ: ç ”ç©¶ä¸å†™ä½œ"},
        "description": {
            "en": """
This module demonstrates **Sequential Multi-Agent Collaboration**.
Instead of one generalist AI, we use two specialist Agents working in a pipeline:

1.  **Researcher Agent**: 
    -   Role: Information gatherer.
    -   Task: Searches for facts about the topic.
    -   Output: A detailed, factual report.
2.  **Writer Agent**: 
    -   Role: Content creator.
    -   Task: Takes the Researcher's report and writes a blog post.
    -   Output: An engaging article.

**Why?** This separation of concerns reduces hallucinations and improves content quality.
""",
            "zh": """
æœ¬æ¨¡å—æ¼”ç¤ºäº† **é¡ºåºå¤šæ™ºèƒ½ä½“åä½œ (Sequential Multi-Agent Collaboration)**ã€‚
æˆ‘ä»¬ä¸å†ä½¿ç”¨ä¸€ä¸ªé€šç”¨çš„ AIï¼Œè€Œæ˜¯è®©ä¸¤ä¸ªä¸“æ‰æ™ºèƒ½ä½“åƒæµæ°´çº¿ä¸€æ ·å·¥ä½œï¼š

1.  **ç ”ç©¶å‘˜ (Researcher)**:
    -   è§’è‰²: ä¿¡æ¯æ”¶é›†è€…ã€‚
    -   ä»»åŠ¡: é’ˆå¯¹ä¸»é¢˜æœé›†äº‹å®ã€‚
    -   è¾“å‡º: ä¸€ä»½è¯¦å®çš„äº‹å®æŠ¥å‘Šã€‚
2.  **ä½œå®¶ (Writer)**:
    -   è§’è‰²: å†…å®¹åˆ›ä½œè€…ã€‚
    -   ä»»åŠ¡: æ ¹æ®ç ”ç©¶å‘˜çš„æŠ¥å‘Šæ’°å†™åšå®¢æ–‡ç« ã€‚
    -   è¾“å‡º: ä¸€ç¯‡å¼•äººå…¥èƒœçš„æ–‡ç« ã€‚

**ä¸ºä»€ä¹ˆï¼Ÿ** è¿™ç§èŒè´£åˆ†ç¦» (Separation of Concerns) èƒ½æœ‰æ•ˆå‡å°‘å¹»è§‰ï¼Œå¹¶æé«˜å†…å®¹è´¨é‡ã€‚
"""
        },
        "topic_label": {"en": "Enter a Topic", "zh": "è¾“å…¥ä¸€ä¸ªä¸»é¢˜"},
        "topic_placeholder": {"en": "e.g., The Future of Quantum Computing, How to bake a cake", "zh": "ä¾‹å¦‚ï¼šé‡å­è®¡ç®—çš„æœªæ¥ï¼Œå¦‚ä½•çƒ¤è›‹ç³•"},
        "start_btn": {"en": "ğŸš€ Start Collaboration", "zh": "ğŸš€ å¼€å§‹åä½œ"},
        "warning_topic": {"en": "Please enter a topic first.", "zh": "è¯·å…ˆè¾“å…¥ä¸€ä¸ªä¸»é¢˜ã€‚"},
        "step_research": {"en": "ğŸ•µï¸â€â™‚ï¸ Researcher is working...", "zh": "ğŸ•µï¸â€â™‚ï¸ ç ”ç©¶å‘˜æ­£åœ¨å·¥ä½œ..."},
        "step_write": {"en": "âœï¸ Writer is working...", "zh": "âœï¸ ä½œå®¶æ­£åœ¨å·¥ä½œ..."},
        "done": {"en": "âœ… Collaboration Finished!", "zh": "âœ… åä½œå®Œæˆï¼"},
        "final_result": {"en": "### ğŸ“ Final Article", "zh": "### ğŸ“ æœ€ç»ˆæ–‡ç« "},
        "error": {"en": "Error occurred: {}", "zh": "å‘ç”Ÿé”™è¯¯: {}"}
    },
    "Finetune_Data": {
        "page_title": {"en": "Finetune Data Prep", "zh": "å¾®è°ƒæ•°æ®å‡†å¤‡"},
        "title": {"en": "ğŸ› ï¸ Fine-tuning Dataset Builder", "zh": "ğŸ› ï¸ å¾®è°ƒæ•°æ®é›†æ„å»ºå™¨"},
        "description": {
            "en": """
**Phase 4.2: Fine-tuning Data Preparation**

To train a specialized model (e.g., a "Legal Assistant" or "Medical Expert"), you cannot just use raw text.
You need to teach the model **how to answer** by providing examples in a specific format (JSONL).

**Format Structure:**
- **System**: The persona (e.g., "You are a lawyer").
- **User**: The question/instruction.
- **Assistant**: The ideal answer you want the model to learn.

Use this tool to build your first dataset!
""",
            "zh": """
**é˜¶æ®µ 4.2: å¾®è°ƒæ•°æ®å‡†å¤‡ (Data Preparation)**

è¦è®­ç»ƒä¸€ä¸ªä¸“ç”¨æ¨¡å‹ï¼ˆä¾‹å¦‚â€œæ³•å¾‹åŠ©æ‰‹â€æˆ–â€œåŒ»ç–—ä¸“å®¶â€ï¼‰ï¼Œä¸èƒ½åªç»™å®ƒçœ‹åŸå§‹æ–‡æ¡£ã€‚
ä½ éœ€è¦é€šè¿‡æä¾›ç‰¹å®šæ ¼å¼ (JSONL) çš„é—®ç­”å¯¹ï¼Œæ•™æ¨¡å‹ **â€œè¯¥æ€ä¹ˆå›ç­”â€**ã€‚

**æ ¸å¿ƒç»“æ„ï¼š**
- **System (äººè®¾)**: æ¨¡å‹çš„èº«ä»½ï¼ˆå¦‚â€œä½ æ˜¯ä¸€åå¾‹å¸ˆâ€ï¼‰ã€‚
- **User (æŒ‡ä»¤)**: ç”¨æˆ·çš„é—®é¢˜æˆ–æŒ‡ä»¤ã€‚
- **Assistant (å›ç­”)**: ä½ å¸Œæœ›æ¨¡å‹å­¦ä¹ çš„â€œæ ‡å‡†ç­”æ¡ˆâ€ã€‚

ä½¿ç”¨æ­¤å·¥å…·æ¥æ„å»ºä½ çš„ç¬¬ä¸€ä¸ªå¾®è°ƒæ•°æ®é›†ï¼
"""
        },
        "system_label": {"en": "System Prompt", "zh": "System Prompt (äººè®¾)"},
        "user_label": {"en": "User Instruction", "zh": "User Instruction (ç”¨æˆ·æŒ‡ä»¤)"},
        "assistant_label": {"en": "Assistant Response (Standard Answer)", "zh": "Assistant Response (æ ‡å‡†ç­”æ¡ˆ)"},
        "add_btn": {"en": "â• Add to Dataset", "zh": "â• æ·»åŠ åˆ°æ•°æ®é›†"},
        "preview_header": {"en": "ğŸ“Š Dataset Preview (JSONL)", "zh": "ğŸ“Š æ•°æ®é›†é¢„è§ˆ (JSONL)"},
        "download_btn": {"en": "ğŸ“¥ Download .jsonl", "zh": "ğŸ“¥ ä¸‹è½½ .jsonl æ–‡ä»¶"},
        "clear_btn": {"en": "ğŸ—‘ï¸ Clear Dataset", "zh": "ğŸ—‘ï¸ æ¸…ç©ºæ•°æ®é›†"},
        "success_add": {"en": "Added 1 record!", "zh": "å·²æ·»åŠ  1 æ¡æ•°æ®ï¼"},
        
        # Enhanced Data Prep Content
        "tab_editor": {"en": "ğŸ“ Data Editor", "zh": "ğŸ“ æ•°æ®ç¼–è¾‘å™¨"},
        "tab_guide": {"en": "ğŸ“š Concept Guide", "zh": "ğŸ“š æ¦‚å¿µæŒ‡å—"},
        "template_label": {"en": "Load Template", "zh": "åŠ è½½æ¨¡æ¿"},
        "template_none": {"en": "None (Custom)", "zh": "æ—  (è‡ªå®šä¹‰)"},
        "template_chat": {"en": "General Chat", "zh": "é€šç”¨å¯¹è¯"},
        "template_code": {"en": "Code Generation", "zh": "ä»£ç ç”Ÿæˆ"},
        "template_medical": {"en": "Medical Consultation", "zh": "åŒ»ç–—å’¨è¯¢"},
        "guide_title": {"en": "Understanding Instruction Tuning Data", "zh": "ç†è§£æŒ‡ä»¤å¾®è°ƒæ•°æ®"},
        "guide_intro": {
            "en": "To fine-tune an LLM, we need to show it examples of **how to follow instructions**.",
            "zh": "ä¸ºäº†å¾®è°ƒ LLMï¼Œæˆ‘ä»¬éœ€è¦ç»™å®ƒå±•ç¤º **â€œå¦‚ä½•éµå¾ªæŒ‡ä»¤â€** çš„ç¤ºä¾‹ã€‚"
        },
        "guide_structure_title": {"en": "The Structure (JSONL)", "zh": "æ ¸å¿ƒç»“æ„ (JSONL)"},
        "guide_structure_desc": {
            "en": "Each line in the file is a separate training example. It usually contains 3 roles:",
            "zh": "æ–‡ä»¶ä¸­çš„æ¯ä¸€è¡Œéƒ½æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„è®­ç»ƒæ ·æœ¬ã€‚é€šå¸¸åŒ…å« 3 ä¸ªè§’è‰²ï¼š"
        },
        "role_system": {"en": "**System**: Sets the behavior/persona.", "zh": "**System (ç³»ç»Ÿ)**: è®¾å®šæ¨¡å‹çš„è¡Œä¸ºæˆ–äººè®¾ã€‚"},
        "role_user": {"en": "**User**: The input/prompt.", "zh": "**User (ç”¨æˆ·)**: ç”¨æˆ·çš„è¾“å…¥æˆ–æŒ‡ä»¤ã€‚"},
        "role_assistant": {"en": "**Assistant**: The ideal output you want the model to learn.", "zh": "**Assistant (åŠ©æ‰‹)**: ä½ å¸Œæœ›æ¨¡å‹å­¦ä¹ çš„ç†æƒ³è¾“å‡ºï¼ˆæ ‡å‡†ç­”æ¡ˆï¼‰ã€‚"},
        "quality_title": {"en": "Quality Checklist", "zh": "é«˜è´¨é‡æ•°æ®æ¸…å•"},
        "checklist_1": {"en": "âœ… **Diversity**: Don't just repeat the same pattern.", "zh": "âœ… **å¤šæ ·æ€§**: ä¸è¦é‡å¤åŒä¸€ç§å¥å¼æˆ–é—®é¢˜ã€‚"},
        "checklist_2": {"en": "âœ… **Correctness**: The 'Assistant' answer must be 100% correct.", "zh": "âœ… **å‡†ç¡®æ€§**: Assistant çš„å›ç­”å¿…é¡»æ˜¯ 100% æ­£ç¡®çš„ï¼ˆå› ä¸ºæ¨¡å‹ä¼šæ¨¡ä»¿å®ƒï¼‰ã€‚"},
        "checklist_3": {"en": "âœ… **Completeness**: Avoid short, lazy answers if you want detailed outputs.", "zh": "âœ… **å®Œæ•´æ€§**: å¦‚æœä½ æƒ³è¦è¯¦ç»†çš„å›ç­”ï¼Œä¸è¦æä¾›ç®€çŸ­ã€æ•·è¡çš„æ ·æœ¬ã€‚"}
    },
    "PEFT_Concepts": {
        "page_title": {"en": "PEFT & LoRA Concepts", "zh": "å¾®è°ƒæŠ€æœ¯åŸç† (PEFT/LoRA)"},
        "title": {"en": "ğŸ§  Fine-tuning & LoRA: Under the Hood", "zh": "ğŸ§  å¾®è°ƒä¸ LoRAï¼šæŠ€æœ¯æ­ç§˜"},
        "tab_concepts": {"en": "Full vs PEFT", "zh": "å…¨é‡å¾®è°ƒ vs PEFT"},
        "tab_lora": {"en": "LoRA Principle", "zh": "LoRA æ ¸å¿ƒåŸç†"},
        "tab_data": {"en": "Data Construction Guide", "zh": "æ•°æ®æ„å»ºæŒ‡å—"},
        
        # Tab 1: Concepts
        "concept_full_title": {"en": "Full Fine-tuning (FFT)", "zh": "å…¨é‡å¾®è°ƒ (Full Fine-tuning)"},
        "concept_full_desc": {
            "en": "Updates **ALL** parameters of the model. Expensive and slow.", 
            "zh": "æ›´æ–°æ¨¡å‹çš„æ‰€æœ‰å‚æ•°ã€‚æˆæœ¬é«˜ï¼Œé€Ÿåº¦æ…¢ï¼Œæ˜¾å­˜éœ€æ±‚æå¤§ã€‚"
        },
        "concept_peft_title": {"en": "Parameter-Efficient Fine-tuning (PEFT)", "zh": "å‚æ•°é«˜æ•ˆå¾®è°ƒ (PEFT)"},
        "concept_peft_desc": {
            "en": "Updates only a **small subset** of parameters (or adds adapters). Fast and cheap.", 
            "zh": "ä»…æ›´æ–°æå°‘é‡çš„å‚æ•°ï¼ˆæˆ–æ·»åŠ é€‚é…å™¨ï¼‰ã€‚é€Ÿåº¦å¿«ï¼Œæˆæœ¬ä½ï¼Œç”šè‡³èƒ½åœ¨æ¶ˆè´¹çº§æ˜¾å¡ä¸Šè¿è¡Œã€‚"
        },
        "analogy": {"en": "ğŸ’¡ Analogy", "zh": "ğŸ’¡ é€šä¿—ç±»æ¯”"},
        "analogy_text": {
            "en": "**FFT**: Rewriting the entire textbook to add a new chapter.\n**PEFT**: Adding a sticky note or a bookmark to the existing book.",
            "zh": "**å…¨é‡å¾®è°ƒ**: ä¸ºäº†å¢åŠ ä¸€ç« æ–°å†…å®¹ï¼ŒæŠŠæ•´æœ¬æ•™ç§‘ä¹¦é‡æ–°æŠ„å†™ä¸€éã€‚\n**PEFT**: åœ¨ä¹¦é‡Œå¤¹ä¸€å¼ ä¾¿åˆ©è´´æˆ–ä¹¦ç­¾ï¼Œåªå†™æ–°å†…å®¹ã€‚"
        },

        # Tab 2: LoRA
        "lora_title": {"en": "LoRA: Low-Rank Adaptation", "zh": "LoRA: ä½ç§©è‡ªé€‚åº”"},
        "lora_desc": {
            "en": "LoRA freezes the pre-trained weights $W_0$ and injects trainable rank decomposition matrices $A$ and $B$.",
            "zh": "LoRA å†»ç»“é¢„è®­ç»ƒæƒé‡ $W_0$ï¼Œå¹¶æ³¨å…¥å¯è®­ç»ƒçš„ä½ç§©åˆ†è§£çŸ©é˜µ $A$ å’Œ $B$ã€‚"
        },
        "formula": {"en": "Formula", "zh": "æ ¸å¿ƒå…¬å¼"},
        "params_saved": {"en": "Parameters Reduced", "zh": "å‚æ•°é‡å‡å°‘"},
        "qlora_note": {"en": "QLoRA = 4-bit Quantization + LoRA (Even less memory!)", "zh": "QLoRA = 4-bit é‡åŒ– + LoRA (æ˜¾å­˜å ç”¨æ›´ä½ï¼)"},

        # Tab 3: Data
        "data_title": {"en": "How to Construct Instruction Data", "zh": "å¦‚ä½•æ„å»ºæŒ‡ä»¤å¾®è°ƒæ•°æ®"},
        "data_step1": {"en": "1. Data Cleaning", "zh": "1. æ•°æ®æ¸…æ´—"},
        "data_step1_desc": {"en": "Remove noise, HTML tags, duplicate punctuation.", "zh": "å»é™¤å™ªå£°ã€HTMLæ ‡ç­¾ã€é‡å¤æ ‡ç‚¹ã€ä¹±ç ç­‰ã€‚"},
        "data_step2": {"en": "2. Instruction Formatting", "zh": "2. æ„é€ æŒ‡ä»¤ (Instruction)"},
        "data_step2_desc": {"en": "Transform raw text into QA pairs or Task-Response pairs.", "zh": "å°†åŸå§‹æ–‡æœ¬è½¬åŒ–ä¸ºâ€œé—®ç­”å¯¹â€æˆ–â€œä»»åŠ¡-å“åº”â€å¯¹ã€‚"},
        "good_bad_example": {"en": "Good vs Bad Examples", "zh": "ä¼˜è´¨ vs åŠ£è´¨ ç¤ºä¾‹"},
        "bad_label": {"en": "âŒ Bad", "zh": "âŒ åŠ£è´¨"},
        "good_label": {"en": "âœ… Good", "zh": "âœ… ä¼˜è´¨"},
        "goto_page7": {"en": "ğŸ‘‰ Go to Data Prep Tool", "zh": "ğŸ‘‰ å‰å¾€æ•°æ®å‡†å¤‡å·¥å…·å®æˆ˜"},

        # Diagram Translations
        "diag_train_data": {"en": "Training Data", "zh": "è®­ç»ƒæ•°æ®"},
        "diag_pretrained": {"en": "Pre-trained Model\\n(10B Params)", "zh": "é¢„è®­ç»ƒæ¨¡å‹\\n(100äº¿å‚æ•°)"},
        "diag_new_model": {"en": "New Model\\n(10B Params)", "zh": "æ–°æ¨¡å‹\\n(100äº¿å‚æ•°)"},
        "diag_update_all": {"en": "Update ALL Weights", "zh": "æ›´æ–°æ‰€æœ‰æƒé‡"},
        
        "diag_pretrained_frozen": {"en": "Pre-trained Model\\n(Frozen)", "zh": "é¢„è®­ç»ƒæ¨¡å‹\\n(å·²å†»ç»“)"},
        "diag_adapter": {"en": "Adapter / LoRA\\n(10M Params)", "zh": "é€‚é…å™¨ / LoRA\\n(1000ä¸‡å‚æ•°)"},
        "diag_output": {"en": "Final Output", "zh": "æœ€ç»ˆè¾“å‡º"},
        "diag_update_adapter": {"en": "Update ONLY Adapter", "zh": "ä»…æ›´æ–°é€‚é…å™¨"},

        # New Beginner Content
        "why_title": {"en": "Why Fine-tune?", "zh": "ä¸ºä»€ä¹ˆéœ€è¦å¾®è°ƒï¼Ÿ"},
        "why_desc": {"en": "General models (like GPT-4) are smart, but specialized models are better at:", "zh": "é€šç”¨æ¨¡å‹ (å¦‚ GPT-4) è™½ç„¶èªæ˜ï¼Œä½†åœ¨ä»¥ä¸‹åœºæ™¯ï¼Œå¾®è°ƒåçš„ä¸“ç”¨æ¨¡å‹æ›´å¼ºï¼š"},
        "use_case_1": {"en": "ğŸ¥ **Domain Knowledge**: Medical, Legal, Finance.", "zh": "ğŸ¥ **æ³¨å…¥é¢†åŸŸçŸ¥è¯†**: åŒ»ç–—ã€æ³•å¾‹ã€é‡‘èç­‰å‚ç›´é¢†åŸŸçš„ä¸“ä¸šæœ¯è¯­ã€‚"},
        "use_case_2": {"en": "ğŸ­ **Style & Tone**: Roleplay, Speaking like a specific person.", "zh": "ğŸ­ **è°ƒæ•´è¯­æ°”é£æ ¼**: è§’è‰²æ‰®æ¼” (å¦‚â€œçŒ«å¨˜â€ã€â€œé«˜æƒ…å•†å®¢æœâ€)ã€æ¨¡ä»¿ç‰¹å®šæ–‡é£ã€‚"},
        "use_case_3": {"en": "ğŸ“‹ **Format Control**: Strict JSON/SQL output.", "zh": "ğŸ“‹ **å›ºå®šè¾“å‡ºæ ¼å¼**: å¼ºè¿«æ¨¡å‹ç¨³å®šè¾“å‡º JSONã€SQL æˆ–ç‰¹å®šä»£ç æ ¼å¼ï¼Œä¾¿äºç¨‹åºè§£æã€‚"},
        
        "rag_vs_ft_title": {"en": "Fine-tuning vs RAG vs Prompting", "zh": "å¾®è°ƒ vs RAG vs æç¤ºè¯å·¥ç¨‹"},
        "comp_prompt": {"en": "ğŸ—£ï¸ **Prompting**", "zh": "ğŸ—£ï¸ **æç¤ºè¯ (Prompt)**"},
        "comp_prompt_desc": {"en": "Temporary instructions. Context window limit.", "zh": "ä¸´æ—¶çš„æŒ‡ä»¤ã€‚åƒâ€œå¯¹äººè¯´ä¸€å¥è¯â€ã€‚ç¼ºç‚¹æ˜¯è®°ä¸ä½ï¼Œä¸”æœ‰é•¿åº¦é™åˆ¶ã€‚"},
        "comp_rag": {"en": "ğŸ“š **RAG (Retrieval)**", "zh": "ğŸ“š **RAG (æ£€ç´¢å¢å¼º)**"},
        "comp_rag_desc": {"en": "Open-book exam. Good for factual retrieval.", "zh": "åƒâ€œå¼€å·è€ƒè¯•â€ã€‚é‡åˆ°é—®é¢˜å…ˆå»ç¿»ä¹¦ (çŸ¥è¯†åº“)ã€‚é€‚åˆä¼ä¸šæ–‡æ¡£é—®ç­”ã€‚"},
        "comp_ft": {"en": "ğŸ§  **Fine-tuning**", "zh": "ğŸ§  **å¾®è°ƒ (Fine-tuning)**"},
        "comp_ft_desc": {"en": "Internalizing knowledge. Muscle memory.", "zh": "åƒâ€œä¸“ä¸šè¿›ä¿®â€ã€‚æŠŠçŸ¥è¯†å†…åŒ–è¿›å¤§è„‘ï¼Œå½¢æˆè‚Œè‚‰è®°å¿†ã€‚é€‚åˆå­¦ä¹ ç‰¹å®šçš„è¯´è¯æ–¹å¼æˆ–å¤æ‚é€»è¾‘ã€‚"},

        "lifecycle_title": {"en": "The Fine-tuning Lifecycle", "zh": "å¾®è°ƒå…¨æµç¨‹"},
        "step_1": {"en": "1. Data Prep", "zh": "1. æ•°æ®å‡†å¤‡"},
        "step_1_desc": {"en": "QA Pairs (JSONL)", "zh": "å‡†å¤‡é—®ç­”å¯¹ (JSONL)"},
        "step_2": {"en": "2. Base Model", "zh": "2. é€‰åŸºåº§æ¨¡å‹"},
        "step_2_desc": {"en": "Qwen/Llama/DeepSeek", "zh": "Qwen/Llama/DeepSeek"},
        "step_3": {"en": "3. LoRA Train", "zh": "3. LoRA è®­ç»ƒ"},
        "step_3_desc": {"en": "GPU Calculation", "zh": "GPU æ˜¾å¡è®¡ç®—"},
        "step_4": {"en": "4. Merge/Serve", "zh": "4. å¯¼å‡ºä¸ä½¿ç”¨"},
        "step_4_desc": {"en": "New Model", "zh": "è·å¾—æ–°æ¨¡å‹"}
    },
    "Video_Subtitle": {
        "page_title": {"en": "AI Video Translator", "zh": "AI è§†é¢‘å­—å¹•ç¿»è¯‘"},
        "title": {"en": "ğŸ¬ AI Video Subtitle Generator & Translator", "zh": "ğŸ¬ AI è§†é¢‘åŒè¯­å­—å¹•ç”Ÿæˆå™¨"},
        "description": {
            "en": """
**Real-time video translation is hard, but Offline Batch Processing is standard.**

This tool demonstrates the full pipeline of **AI Video Localization**:
1.  **Extract Audio**: Get sound from video file.
2.  **ASR (Whisper)**: Speech-to-Text with high accuracy.
3.  **LLM Translation**: Translate subtitles segment by segment.
4.  **Synthesis**: Generate WebVTT subtitles and overlay on video.
""",
            "zh": """
**è™½ç„¶Webç«¯å¾ˆéš¾åšåˆ°â€œè¾¹æ’­è¾¹è¯‘â€çš„å®æ—¶æµï¼Œä½†â€œç¦»çº¿å¤„ç†â€æ˜¯å·¥ä¸šç•Œçš„æ ‡å‡†æ–¹æ¡ˆã€‚**

æœ¬å·¥å…·æ¼”ç¤ºäº† **AI è§†é¢‘æœ¬åœ°åŒ–** çš„å…¨æµç¨‹ï¼š
1.  **éŸ³é¢‘æå–**: ä»è§†é¢‘æ–‡ä»¶ä¸­åˆ†ç¦»éŸ³è½¨ã€‚
2.  **è¯­éŸ³è½¬å†™ (ASR)**: ä½¿ç”¨ OpenAI Whisper æ¨¡å‹è¿›è¡Œé«˜ç²¾åº¦è¯­éŸ³è¯†åˆ«ã€‚
3.  **LLM ç¿»è¯‘**: å°†è¯†åˆ«å‡ºçš„è‹±æ–‡å­—å¹•é€å¥ç¿»è¯‘æˆä¸­æ–‡ã€‚
4.  **å­—å¹•åˆæˆ**: ç”Ÿæˆ WebVTT åŒè¯­å­—å¹•æ–‡ä»¶ï¼Œå¹¶æŒ‚è½½åˆ°æ’­æ”¾å™¨ã€‚
"""
        },
        "upload_label": {"en": "Upload a Video (MP4/MOV)", "zh": "ä¸Šä¼ è§†é¢‘æ–‡ä»¶ (MP4/MOV/AVI)"},
        "process_btn": {"en": "ğŸš€ Start Processing", "zh": "ğŸš€ å¼€å§‹ç”ŸæˆåŒè¯­å­—å¹•"},
        "processing_step1": {"en": "1ï¸âƒ£ Extracting Audio...", "zh": "1ï¸âƒ£ æ­£åœ¨æå–éŸ³é¢‘..."},
        "processing_step2": {"en": "2ï¸âƒ£ Transcribing with Whisper (ASR)...", "zh": "2ï¸âƒ£ æ­£åœ¨è¿›è¡Œè¯­éŸ³è¯†åˆ« (Whisper)..."},
        "processing_step3": {"en": "3ï¸âƒ£ Translating with LLM...", "zh": "3ï¸âƒ£ æ­£åœ¨è°ƒç”¨å¤§æ¨¡å‹ç¿»è¯‘..."},
        "processing_step3_progress": {"en": "Translating segment {}/{}...", "zh": "æ­£åœ¨ç¿»è¯‘ç¬¬ {}/{} å¥..."},
        "success": {"en": "âœ… Done! Enjoy your video.", "zh": "âœ… å¤„ç†å®Œæˆï¼è¯·è§‚çœ‹ä¸‹æ–¹è§†é¢‘ã€‚"},
        "download_vtt": {"en": "ğŸ“¥ Download Subtitles (.vtt)", "zh": "ğŸ“¥ ä¸‹è½½å­—å¹•æ–‡ä»¶ (.vtt)"},
        "error_no_model": {"en": "Please configure LLM in 'Basic Chat' first!", "zh": "è¯·å…ˆåœ¨ 'åŸºç¡€å¯¹è¯' é¡µé¢é…ç½®æ¨¡å‹ APIï¼"},
        "model_loading": {"en": "Loading Whisper model (first time may take a while)...", "zh": "æ­£åœ¨åŠ è½½ Whisper æ¨¡å‹ (é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½ï¼Œè¯·è€å¿ƒç­‰å¾…)..."}
    }
}

def get_text(page, key, lang="zh"):
    """
    Get translated text.
    :param page: Page key (e.g., "Home", "Basic_Chat")
    :param key: Text key
    :param lang: Language code ("en" or "zh")
    :return: Translated text
    """
    try:
        return TRANSLATIONS[page][key][lang]
    except KeyError:
        return f"MISSING TRANSLATION: {page}.{key}.{lang}"

def init_lang():
    """Initialize language state."""
    if "lang" not in st.session_state:
        st.session_state.lang = "zh"

def lang_selector():
    """Render language selector (Fixed Top-Right Dropdown)."""
    lang_options = {"ä¸­æ–‡": "zh", "English": "en"}
    
    # Inject CSS for fixed positioning and styling
    st.markdown(
        """
        <style>
        /* Target the specific selectbox container by assuming it's the first one in the main area */
        /* Since we render it first, we can target the first stSelectbox in the main container */
        
        div[data-testid="stSelectbox"] {
            /* We can't target just *this* one easily without a unique class, 
               but we can try targeting the one that is inside the container we are about to create?
               No, Streamlit flattens logic. 
               
               Strategy: Target the stSelectbox that is FIRST child of the FIRST VerticalBlock?
            */
        }
        
        /* 
           Robust Approach:
           Target the element by its proximity to the top of the page.
           But to be safe, we will assume this is the first selectbox.
        */
        
        div[data-testid="stSelectbox"]:nth-of-type(1) {
            position: fixed !important;
            top: 10px; /* Adjusted for taller box */
            right: 180px;
            width: 120px;
            z-index: 1000001;
        }

        /* Adjust the inner input box to be transparent and minimal */
        div[data-testid="stSelectbox"]:nth-of-type(1) > div > div {
            min-height: 40px; /* Increased height to accommodate descenders */
            height: 40px;
            background-color: transparent;
            border: none;
            color: inherit;
            overflow: visible; /* Ensure text isn't clipped */
        }
        
        /* Remove the focus outline/shadow to keep it clean */
        div[data-testid="stSelectbox"]:nth-of-type(1) > div > div:focus-within {
            box-shadow: none;
            border: 1px solid rgba(49, 51, 63, 0.2);
        }
        
        /* Adjust the dropdown text alignment and padding */
        div[data-testid="stSelectbox"]:nth-of-type(1) div[data-testid="stMarkdownContainer"] p {
            font-size: 0.9rem;
            font-weight: 500;
            white-space: nowrap;
            overflow: visible;
            line-height: 40px; /* Center text vertically */
            padding-bottom: 2px; /* Extra nudge for descenders */
        }

        /* Adjust the dropdown arrow container */
        div[data-testid="stSelectbox"]:nth-of-type(1) > div > div > div[role="button"] {
             line-height: 40px;
        }
        
        /* Hide the upper right decoration if it interferes */
        header[data-testid="stHeader"] {
            z-index: 1000000;
        }
        </style>
        """, 
        unsafe_allow_html=True
    )

    # Render the selectbox directly (no columns, to keep DOM simple)
    st.selectbox(
        "Language",
        options=list(lang_options.keys()),
        index=0 if st.session_state.get("lang", "zh") == "zh" else 1,
        key="lang_select",
        on_change=_update_lang,
        label_visibility="collapsed"
    )

def _update_lang():
    """Callback to update session state when language changes."""
    selected_label = st.session_state.lang_select
    lang_map = {"ä¸­æ–‡": "zh", "English": "en"}
    st.session_state.lang = lang_map[selected_label]


def render_sidebar():
    """
    Render custom sidebar with translated navigation.
    Hides the default Streamlit sidebar navigation.
    """
    lang = st.session_state.get("lang", "zh")
    
    # CSS to hide default sidebar nav
    st.markdown(
        """
        <style>
        [data-testid="stSidebarNav"] {
            display: none;
        }
        </style>
        """,
        unsafe_allow_html=True
    )
    
    with st.sidebar:
        st.header(get_text("Home", "page_title", lang) if lang == "zh" else "Navigation")
        
        # Define pages
        pages = [
            {"page": "Home.py", "label": get_text("Home", "page_title", lang), "icon": "ğŸ "},
            {"page": "pages/1_Basic_Chat.py", "label": get_text("Basic_Chat", "page_title", lang), "icon": "ğŸ¤–"},
            {"page": "pages/2_RAG_Rerank.py", "label": get_text("RAG_Rerank", "page_title", lang), "icon": "ğŸ“š"},
            {"page": "pages/3_Knowledge_Graph.py", "label": get_text("Knowledge_Graph", "page_title", lang), "icon": "ğŸ•¸ï¸"},
            {"page": "pages/4_Agent_Basics.py", "label": get_text("Agent_Basics", "page_title", lang), "icon": "ğŸ§©"},
            {"page": "pages/5_Agent_Workflow.py", "label": get_text("Agent_Workflow", "page_title", lang), "icon": "ğŸ”„"},
            {"page": "pages/6_Multi_Agent_Collaboration.py", "label": get_text("Multi_Agent", "page_title", lang), "icon": "ğŸ¤"},
            {"page": "pages/7_Finetune_Data_Prep.py", "label": get_text("Finetune_Data", "page_title", lang), "icon": "ğŸ› ï¸"},
            {"page": "pages/8_PEFT_LoRA_Concepts.py", "label": get_text("PEFT_Concepts", "page_title", lang), "icon": "ğŸ§ "},
        ]
        
        for p in pages:
            st.page_link(p["page"], label=p["label"], icon=p["icon"])
